{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# The morphology of human settlements based upon building configurations","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#-------------------------------------------------------------------------------\n# Program Name:        Deep Convolutional Neural Network (DCNN) for built informality mapping\n# Purpose:     Test DCNN on mapping degrees of deprivation\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# Input data files are available in the read-only \"../input/\" directory\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# Version:     0.1 \n#              Functionalities:\n#              1. Loading data;\n#              2. Preparing training and testing sets;\n#              3. Setting up experiment, including model configuration and training session;\n#              4. Predicting.\n\n# Author:      Jiong (Jon) Wang\n#\n# Created:     24/08/2020\n# Copyright:   (c) JonWang 2020\n# Licence:     <your licence>\n#-------------------------------------------------------------------------------\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, model_from_json, load_model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    UpSampling2D,\n    MaxPooling2D,\n    Input,\n    Conv2DTranspose,\n    Flatten,\n    BatchNormalization,\n    Activation,\n    Concatenate\n)\nfrom tensorflow.keras.layers import RepeatVector, Reshape\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom tensorflow.keras.applications import MobileNetV2\nfrom scipy import interpolate\nfrom osgeo import gdal_array\nfrom pathlib import Path\nfrom functools import partial\nfrom sklearn.metrics import jaccard_score\nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport os\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 00: View files and versions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#for dirname, _, filenames in os.walk('/kaggle/input/building'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n        \nprint('\\nUsing tensorflow version %s' % (tf.__version__))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 01: Load and organize images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# load rasters: base image along with its label\n# Stack base image and label into a list of array\ndef load_rasters(path, subUL, band_ind):  # Subset from original raster with extent and upperleft coord\n    \"\"\"Load training data pairs (two high resolution images and two low resolution images)\"\"\"\n    file_list = path  # List image name\n    assert len(file_list) == 2\n\n    # Ensure the order of the list: base image first !!\n    for file in file_list:  # Organize file list\n        img_name = str(file)\n        if 'image' in img_name:\n            base = file\n        elif 'label' in img_name:\n            label = file\n    file_list = [base, label]\n    \n    stack = []  # Stack base and label together into a 3D array\n    for file in file_list:\n        if 'image' in str(file):\n            data = gdal_array.LoadFile(str(file), xoff=subUL[0], yoff=subUL[1]) #.astype(np.int),ysize=extent[1],xsize=extent[0]\n            print(data.shape)\n            data = data[tuple(band_ind),:,:]  # Worldview image with 3rd dimension at first\n            data = np.transpose(data,(1,2,0))  # Transpose 3rd to last \n            stack.append(data)\n        else:\n            data = gdal_array.LoadFile(str(file), xoff=subUL[0], yoff=subUL[1]) #.astype(np.int),xsize=extent[0],ysize=extent[1]\n            if len(data.shape)==3:\n                data = data[0,:,:]/255.0\n            data = data[:,:,np.newaxis]\n            stack.append(data)\n#        image = Image.fromarray(data)\n#        data = nan_remover(data)\n#        setattr(image, 'filename', file)\n    # Ensure the size of base and label is are consistent\n    assert stack[0].shape[0] == stack[-1].shape[0]\n    assert stack[0].shape[1] == stack[-1].shape[1]\n    return stack[:-1], stack[-1]\n\n\n# Clean the NaN values\ndef nan_remover(array):\n    x = np.arange(0, array.shape[1])\n    y = np.arange(0, array.shape[0])\n    # Masking invalid values\n    array = np.ma.masked_invalid(array)\n    xx, yy = np.meshgrid(x, y)\n    # Getting only the valid values\n    x1 = xx[~array.mask]\n    y1 = yy[~array.mask]\n    newarr = array[~array.mask]\n    array_interp = interpolate.griddata((x1, y1), newarr.ravel(),\n                              (xx, yy), method='nearest')\n    # Clean the edge\n    bad_indexes = np.isnan(array_interp)\n    good_indexes = np.logical_not(bad_indexes)\n    good_data = array_interp[good_indexes]\n    interpolated = np.interp(bad_indexes.nonzero()[0], good_indexes.nonzero()[0], good_data)\n    array_interp[bad_indexes] = interpolated\n    return array_interp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 02: Prepare data for train, val, test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample patches from an image band/layer\n# Stride controls the overlap of patches\ndef gen_patches(image, size, stride):\n    \"\"\"Segment input images into patches\"\"\"\n    if not isinstance(size, tuple):  # Ensure format is tuple\n        size = (size, size)\n    if stride is None:\n        stride = size\n    elif not isinstance(stride, tuple):\n        stride = (stride, stride)\n    # Columns in priority\n    for i in range(0, image.shape[0] - size[0] + 1, stride[0]):  # One patch every stride\n        for j in range(0, image.shape[1] - size[1] + 1, stride[1]):\n            yield image[i:i + size[0], j:j + size[1], :]  # If Pillow Image is used: image.crop([i, j, i + size[0], j + size[1]])\n\n\n# Advanced version of patch sampling\n# Sample patches at target areas with criteria, such as label size\ndef gen_patches_ctrl():  # With controlled position\n    \n    return None\n\n\n# Generate patches for all layers/bands in stack\ndef stack_to_patches(stack, size, stride, patches):\n#    assert len(stack) == 4\n    for i in range(len(stack)):  # Loop over the layers/bands in the stack\n        # If Pillow Image: img_to_array(img)\n        patches[i] += [img*1.0 for img in gen_patches(stack[i], size, stride)]\n\n\n# Arrange training and validation sets from the patches\ndef load_train_set(data_dir, subUL, band_ind, size, stride):\n    # Load image data from training folder\n    patches = [[] for _ in range(2)]  # Empty list to store patches for each layer/band in stack\n    image_list = [name for name in Path(data_dir/'train/image').glob('*.tif')]  # Loop over all images\n    label_list = [name for name in Path(data_dir/'train/label').glob('*.tif')]  # Loop over all labels\n    all_list = {'image':image_list,'label':label_list}\n    df = pd.DataFrame(all_list, columns=['image','label'])\n    \n    for ind, row in df.iterrows():  # Loop over names of all image, label pairs\n        print('loading image pairs from {} and {}'.format(row['image'], row['label']))\n        train_path = [row['image'], row['label']]\n        stack = load_rasters(train_path, subUL, band_ind)\n        stack = [*stack[0], stack[1]]\n        # subset samples into patches\n        stack_to_patches(stack, size, stride, patches)\n            \n    # Split patches into training and validation sets        \n    patch_train = [[] for _ in range(2)]\n    patch_val = [[] for _ in range(2)]\n    for i in range(2):\n        patch_train[i] = np.stack(patches[i][:int(len(patches[i])*0.7)])\n        patch_val[i] = np.stack(patches[i][int(len(patches[i])*0.7):])\n    # Return 4-dimensional array (number, height, width, channel)\n    return patch_train[:-1], patch_train[-1], patch_val[:-1], patch_val[-1]\n\n\n# Arrange test set by using another set of raster input\ndef load_test_set(stack, block_size):\n    assert len(stack) == 2    \n    stack = [*stack[0], stack[1]]  # Update stack by split tuple into list\n    patches = [[] for _ in range(len(stack))]  # Stack length already changed\n    stack_to_patches(stack, size=block_size, stride=None, patches=patches)\n\n    for i in range(len(stack)):\n        patches[i] = np.stack(patches[i])\n    return patches[:-1], patches[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 03: Customize loss function metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Jaccard index realized as intersection over union (iou)\ndef mean_iou(y_true, y_pred):\n    # Consider prediction greater than 0.5\n    y_pred = K.cast(K.greater(y_pred, .5), dtype='float32') # .5 is the threshold\n    inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)\n    union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter\n    return K.mean((inter + K.epsilon()) / (union + K.epsilon()))\n\n\n# Covariance\ndef cov(y_true, y_pred):\n    return K.mean((y_true - K.mean(y_true)) * K.transpose((y_pred - K.mean(y_pred))))\n\n\n# Correlation\ndef r2(y_true, y_pred):\n    # mean calls tensor property instead of ndarray\n    tf_true = y_true\n    if not isinstance(y_true, tf.Tensor):\n        tf_true = tf.convert_to_tensor(y_true)\n    res = K.sum(K.square(y_true - y_pred))\n    tot = K.sum(K.square(y_true - K.mean(tf_true)))\n    return 1 - res / (tot + K.epsilon())\n\n\n# Signal-to-noise ratio\ndef psnr(y_true, y_pred, data_range=50):\n    #Peak signal-to-noise ratio averaged over samples and channels\n    mse = K.mean(K.square(y_true - y_pred), axis=(-3, -2))\n    return K.mean(20 * K.log(data_range / K.sqrt(mse)) / np.log(10))\n\n\n# structural similarity measurement system\ndef ssim(y_true, y_pred, data_range=50):\n    \"\"\"structural similarity measurement system.\"\"\"\n    K1 = 0.01\n    K2 = 0.03\n\n    mu_x = K.mean(y_pred)\n    mu_y = K.mean(y_true)\n\n    sig_x = K.std(y_pred)\n    sig_y = K.std(y_true)\n    sig_xy = cov(y_true, y_pred)\n\n    L = data_range\n    C1 = (K1 * L) ** 2\n    C2 = (K2 * L) ** 2\n\n    return ((2 * mu_x * mu_y + C1) * (2 * sig_xy * C2) /\n            (mu_x ** 2 + mu_y ** 2 + C1) * (sig_x ** 2 + sig_y ** 2 + C2))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 04: Model options","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# MobileNetV2 Encoder for U-net\ndef m_u_net(img):\n    inputs = Input(shape=img.shape[-3:], name=\"input_image\")\n    \n    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=1.3)\n    #encoder.trainable=False\n    skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\", \"block_6_expand_relu\"]\n    encoder_output = encoder.get_layer(\"block_13_expand_relu\").output\n    \n    f = [16, 32, 48, 64]\n    x = encoder_output\n    for i in range(1, len(skip_connection_names)+1, 1):\n        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n        x = UpSampling2D((2, 2))(x)\n        x = Concatenate()([x, x_skip])\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        \n    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n    x = Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs, x)\n    return model\n\n# U-net \ndef u_net(img):\n    inputs = Input(shape=img.shape[-3:])\n    conv1_1 = Conv2D(16, (3, 3), padding='same')(inputs)\n    bn1_1 = BatchNormalization(axis=3)(conv1_1)\n    relu1_1 = Activation('relu')(bn1_1)\n    conv1_2 = Conv2D(16, (3, 3), padding='same')(relu1_1)\n    bn1_2 = BatchNormalization(axis=3)(conv1_2)\n    relu1_2 = Activation('relu')(bn1_2)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(relu1_2)\n    \n    conv2_1 = Conv2D(32, (3, 3), padding='same')(pool1)\n    bn2_1 = BatchNormalization(axis=3)(conv2_1)\n    relu2_1 = Activation('relu')(bn2_1)\n    conv2_2 = Conv2D(32, (3, 3), padding='same')(relu2_1)\n    bn2_2 = BatchNormalization(axis=3)(conv2_2)\n    relu2_2 = Activation('relu')(bn2_2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(relu2_2)\n    \n    conv3_1 = Conv2D(64, (3, 3), padding='same')(pool2)\n    bn3_1 = BatchNormalization(axis=3)(conv3_1)\n    relu3_1 = Activation('relu')(bn3_1)\n    conv3_2 = Conv2D(64, (3, 3), padding='same')(relu3_1)\n    bn3_2 = BatchNormalization(axis=3)(conv3_2)\n    relu3_2 = Activation('relu')(bn3_2)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(relu3_2)\n    \n    conv4_1 = Conv2D(128, (3, 3), padding='same')(pool3)\n    bn4_1 = BatchNormalization(axis=3)(conv4_1)\n    relu4_1 = Activation('relu')(bn4_1)\n    conv4_2 = Conv2D(128, (3, 3), padding='same')(relu4_1)\n    bn4_2 = BatchNormalization(axis=3)(conv4_2)\n    relu4_2 = Activation('relu')(bn4_2)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(relu4_2)\n    \n    conv5_1 = Conv2D(256, (3, 3), padding='same')(pool4)\n    bn5_1 = BatchNormalization(axis=3)(conv5_1)\n    relu5_1 = Activation('relu')(bn5_1)\n    conv5_2 = Conv2D(256, (3, 3), padding='same')(relu5_1)\n    bn5_2 = BatchNormalization(axis=3)(conv5_2)\n    relu5_2 = Activation('relu')(bn5_2)\n    \n    up6 = Concatenate()([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(relu5_2), relu4_2])\n    conv6_1 = Conv2D(128, (3, 3), padding='same')(up6)\n    bn6_1 = BatchNormalization(axis=3)(conv6_1)\n    relu6_1 = Activation('relu')(bn6_1)\n    conv6_2 = Conv2D(128, (3, 3), padding='same')(relu6_1)\n    bn6_2 = BatchNormalization(axis=3)(conv6_2)\n    relu6_2 = Activation('relu')(bn6_2)\n    \n    up7 = Concatenate()([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(relu6_2), relu3_2])\n    conv7_1 = Conv2D(64, (3, 3), padding='same')(up7)\n    bn7_1 = BatchNormalization(axis=3)(conv7_1)\n    relu7_1 = Activation('relu')(bn7_1)\n    conv7_2 = Conv2D(64, (3, 3), padding='same')(relu7_1)\n    bn7_2 = BatchNormalization(axis=3)(conv7_2)\n    relu7_2 = Activation('relu')(bn7_2)\n    \n    up8 = Concatenate()([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(relu7_2), relu2_2])\n    conv8_1 = Conv2D(32, (3, 3), padding='same')(up8)\n    bn8_1 = BatchNormalization(axis=3)(conv8_1)\n    relu8_1 = Activation('relu')(bn8_1)\n    conv8_2 = Conv2D(32, (3, 3), padding='same')(relu8_1)\n    bn8_2 = BatchNormalization(axis=3)(conv8_2)\n    relu8_2 = Activation('relu')(bn8_2)\n    \n    up9 = Concatenate()([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(relu8_2), relu1_2])\n    conv9_1 = Conv2D(16, (3, 3), padding='same')(up9)\n    bn9_1 = BatchNormalization(axis=3)(conv9_1)\n    relu9_1 = Activation('relu')(bn9_1)\n    conv9_2 = Conv2D(16, (3, 3), padding='same')(relu9_1)\n    bn9_2 = BatchNormalization(axis=3)(conv9_2)\n    relu9_2 = Activation('relu')(bn9_2)\n    \n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(relu9_2)\n    \n    model = Model(inputs=[inputs], outputs=[conv10])\n    print(model.summary())\n    \n    return model\n\n\ndef get_model(name):\n    \"\"\"Get model function from the name space in strings\"\"\"\n    return globals()[name]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 05: Train and predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Define an experiment for training and test session\nclass Experiment(object):\n    def __init__(self, load_set, build_model, optimizer, save_dir='.'):\n        self.load_set = load_set\n        self.build_model = build_model\n        self.optimizer = optimizer\n        self.save_dir = Path(save_dir)\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n\n        self.config_file = self.save_dir / 'config.yaml'\n        self.model_file = self.save_dir / 'model.hdf5'\n        self.visual_file = self.save_dir / 'model.eps'\n\n        self.train_dir = self.save_dir / 'train'\n        self.train_dir.mkdir(exist_ok=True)\n        self.history_file = self.train_dir / 'history.csv'\n        self.weights_dir = self.train_dir / 'weights'\n        self.weights_dir.mkdir(exist_ok=True)\n\n        self.test_dir = self.save_dir / 'test'\n        self.test_dir.mkdir(exist_ok=True)\n\n    def weights_file(self, epoch=None):\n        if epoch is None:\n            return self.weights_dir / 'ep{epoch:04d}.hdf5'\n        else:\n            return self.weights_dir / 'ep{:04d}.hdf5'.format(epoch)\n\n    @property\n    def latest_epoch(self):\n        try:\n            return pd.read_csv(str(self.history_file))['epoch'].iloc[-1]\n        except (FileNotFoundError, pd.io.common.EmptyDataError):\n            pass\n        return -1\n\n    @staticmethod\n    def _ensure_dimension(array, dim):\n        while len(array.shape) < dim:\n            array = array[np.newaxis, ...]\n        return array\n\n    @staticmethod\n    def _ensure_channel(array, c):\n        return array[..., c:c + 4]\n\n    @staticmethod\n    def validate(array):\n        array = Experiment._ensure_dimension(array, 4)\n        array = Experiment._ensure_channel(array, 0)\n        return array\n\n    def compile(self, model):\n        \"\"\"Compile model with default settings.\"\"\"\n        model.compile(optimizer=self.optimizer, loss='binary_crossentropy', metrics=[mean_iou])\n        return model\n\n    def train(self, data_dir, epochs, band_ind, resume=True):\n        # Load and process data\n        x_train, y_train, x_val, y_val = self.load_set()\n        assert len(x_train) == len(x_val)\n        for i in range(1):\n            x_train[i], x_val[i] = [self.validate(x) for x in [x_train[i], x_val[i]]]\n        y_train, y_val = [self.validate(y) for y in [y_train, y_val]]\n\n        # Compile model\n        model = self.compile(self.build_model(*x_train))\n        model.summary()\n        #self.config_file.write_text(model.to_yaml())\n        #plot_model(model, to_file=str(self.visual_file), show_shapes=False)\n\n        # Inherit weights\n        if resume:\n            latest_epoch = self.latest_epoch\n            if latest_epoch > -1:\n                weights_file = self.weights_file(epoch=latest_epoch)\n                model.load_weights(str(weights_file))\n            initial_epoch = latest_epoch + 1\n        else:\n            initial_epoch = 0\n\n        # Set up callbacks\n        callbacks = []\n        callbacks += [ModelCheckpoint(str(self.model_file))]\n#        callbacks += [ModelCheckpoint(str(self.weights_file()), save_weights_only=True)]\n        callbacks += [CSVLogger(str(self.history_file), append=resume)]\n        callbacks += [ReduceLROnPlateau(factor=0.5, cooldown=0, patience=30, min_lr=0.5e-5)]\n\n        # Train\n        model.fit(x_train, y_train, batch_size=16, epochs=epochs, callbacks=callbacks,\n                  validation_data=(x_val, y_val), initial_epoch=initial_epoch)\n\n        # Plot metrics history\n        prefix = str(self.history_file).rsplit('.', maxsplit=1)[0]\n        df = pd.read_csv(str(self.history_file))\n        epoch = df['epoch']\n        for metric in ['Loss', 'mean_iou']:\n            train = df[metric.lower()]\n            val = df['val_' + metric.lower()]\n            plt.figure()\n            plt.plot(epoch, train, label='train')\n            plt.plot(epoch, val, label='val')\n            plt.legend(loc='best')\n            plt.xlabel('Epoch')\n            plt.ylabel(metric)\n            plt.savefig('.'.join([prefix, metric.lower(), 'png']))\n            plt.close()\n\n    def test_on_image(self, test_dir, output_dir, subUL, band_ind, \n                      block_size, metrics=[jaccard_score]):\n        # Load images\n        print('Loading test image from {}'.format(test_dir))\n        input_images, valid_image = load_rasters(test_dir, subUL, band_ind)\n        assert input_images[0].shape[-1] == len(band_ind)\n        name = input_images[-1].filename.name if hasattr(input_images[-1], 'filename') else ''\n        print('Predict on image {}'.format(name))\n        \n        # Pad input image as multiple of block size\n        input_row, input_col = input_images[0].shape[0], input_images[0].shape[1]\n        input_images[0] = np.lib.pad(input_images[0], ((0, block_size[0]-input_row%block_size[0]), \n                                           (0, block_size[1]-input_col%block_size[1]),(0,0)), 'edge')\n\n        # Generate output image and measure run time\n        # The shape of the x_inputs (numbers, height, width, channels)\n        x_inputs = [self.validate(img_to_array(im)) for im in input_images]\n#        assert x_inputs[0].shape[1] % block_size[0] == 0\n#        assert x_inputs[0].shape[2] % block_size[1] == 0\n        x_train, _ = load_test_set((input_images, valid_image), block_size=block_size)\n\n        model = self.compile(self.build_model(*x_train))\n        if self.model_file.exists():\n            model.load_weights(str(self.model_file))\n\n        t_start = time.perf_counter()\n        y_preds = model.predict(x_train, batch_size=1)  # 4-dimensional array with batch size\n        # map predicted patches back to original image extent\n        y_pred = np.empty((input_images[0].shape[0], input_images[0].shape[1], 1), dtype=np.float32)\n        row_step = block_size[0]\n        col_step = block_size[1]\n        rows = x_inputs[0].shape[1] // block_size[0]\n        cols = x_inputs[0].shape[2] // block_size[1]\n        count = 0\n        for i in range(rows):\n            for j in range(cols):\n                y_pred[i * row_step:(i + 1) * row_step, j * col_step:(j + 1) * col_step] = y_preds[count]\n                count += 1\n        assert count == rows * cols\n        y_pred = y_pred[:valid_image.shape[0],:valid_image.shape[1]]  # Cut back to unpadded size\n        \n        # Plot prediction and reference\n        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(24,10))\n        ax1.imshow(y_pred[:,:,0],'gray')\n        ax1.set_title('Prediction')\n        ax2.imshow(input_images[0])\n        ax2.set_title('Reference')\n\n        t_end = time.perf_counter()\n\n        # Record metrics\n        row = pd.Series()\n        row['name'] = name\n        row['time'] = t_end - t_start\n        y_true = self.validate(img_to_array(valid_image))\n        y_pred = self.validate(y_pred)\n        for metric in metrics:\n#            row[metric.__name__] = K.eval(metric(y_true, y_pred))\n            row[metric.__name__] = metric(y_true[0].squeeze(), \n               (y_pred[0].squeeze()>.5).astype(int), average='macro')\n\n        prototype = str(valid_image.filename) if hasattr(valid_image, 'filename') else None\n        gdal_array.SaveArray(y_pred[0].squeeze().astype(np.int16),\n                             str(output_dir / name),\n                             prototype=prototype)\n        return row\n    \n    def test(self, data_dir, subUL, band_ind, block_size=(500, 500), metrics=[jaccard_score]):\n        test_set='test'\n        print('Testing...')\n        output_dir = self.test_dir/test_set\n        output_dir.mkdir(exist_ok=True)\n\n        # Evaluate metrics on each image\n        # Different from training that load all images at once before training\n        # test_on_image is put in the loop called for each image\n        image_list = [name for name in Path(data_dir/test_set/'image').glob('*.tif')]  # Loop over all images\n        label_list = [name for name in Path(data_dir/test_set/'label').glob('*.tif')]  # Loop over all labels\n        all_list = {'image':image_list,'label':label_list}\n        df = pd.DataFrame(all_list, columns=['image','label'])\n        \n        rows = []\n        for ind, row in df.iterrows():  # Loop over names of all image, label pairs\n            print('loading image pairs from {} and {}'.format(row['image'], row['label']))\n            test_path = [row['image'], row['label']]\n            rows += [self.test_on_image(test_path, output_dir, subUL, band_ind, \n                                        block_size=block_size, metrics=metrics)]\n        df = pd.DataFrame(rows)\n        # Compute average metrics\n        row = pd.Series()\n        row['name'] = 'average'\n        for col in df:\n            if col != 'name':\n                row[col] = df[col].mean()\n        df = df.append(row, ignore_index=True)\n        df.to_csv(str(self.test_dir / '{}/metrics.csv'.format(test_set)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functionality 06: Running","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#------------------------\n# Set working directory and parameters\n#------------------------\n\n# Working directory\n#repo_dir = Path('__file__').parents[0]\ndata_dir = Path('../input/building/sample_data3/')\nsave_dir = Path('../output/kaggle/working')\n\n# Affiliated parameters from JSON file\n#with open('parameter2.json', 'r') as read_file:\n#    param = json.load(read_file)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#------------------------\n# Experiment configure and compile\n#------------------------\n\n# Input training patch dimensions\nsize=64  # param['size']\nstride=64  # param['stride']  # Sampling stride\n#extent = param['extent']\nepochs=30 #param['epochs']\n# Index of selected band\nbands=[3,2,1]  # param['band_ind']\nband_ind=[i-1 for i in bands]\n# Subset study area\nsubUL=[0,0]  # param['subUL']\nblock_size=tuple([256,256])  # tuple(param['block_size'])\n\n\nbuild_model = get_model('m_u_net') #(param['model']['name'])\n\noptimizer = getattr(optimizers, 'Adam')  # getattr(optimizers, param['optimizer']['name'])\noptimizer = optimizer(lr=1e-4, decay=1e-5)  # optimizer(**param['optimizer']['params'])\n\n#if 'optimizer' in param:\n#    optimizer = getattr(optimizers, 'Adam')  # getattr(optimizers, param['optimizer']['name'])\n#    optimizer = optimizer(lr=1e-4, decay=1e-5)  # optimizer(**param['optimizer']['params'])\n#else:\n#    optimizer = 'Adam'\n       \n# Simple version of data loading functionality\nload_set = partial(load_train_set, data_dir, \n                   subUL, band_ind, size, stride)\n\n# Setup experiment\nexpt = Experiment(load_set=load_set,\n                  build_model=build_model, optimizer=optimizer,\n                  save_dir='results')  # save_dir=param['save_dir']\n               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#------------------------\n# Train\n#------------------------    \nprint('training process...')\nexpt.train(data_dir=data_dir, band_ind=band_ind, \n           epochs=epochs, resume=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#------------------------\n# Test\n#------------------------    \n# Evaluation\nprint('evaluation process...')\nexpt.test(data_dir=data_dir, subUL=subUL, \n          band_ind=band_ind, block_size=block_size)  # lr_block_size=lr_block_size\n#    for test_set in param['test_sets']:\n#        expt.test(test_set=test_set, lr_block_size=lr_block_size)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}